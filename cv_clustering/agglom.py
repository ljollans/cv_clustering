import numpy as np
import pickle
from cv_clustering.beta_aggregate import vector_mse
import sys
sys.path.append('/Users/lee_jollans/PycharmProjects/mdd_clustering/cv_clustering')
from sklearn.cluster import AgglomerativeClustering


def doagglomchks(link, mf,n_cv_folds, f, n_k, filepath2use):

    # link: 0:Ward, 1:Complete, 2:Average linkage type for AgglomerativeClustering
    # mf: main CV fold (to retrieve the correct nested CV files)
    # n_cv_folds : number of nested CV folds (to make sure all files and the correct files are retrieved)
    # n : number of features (to initialize the array without having to load a file first)
    # n_k: number of values of k that were tested

    # filepath2use consists of input_filediri + sets[s] + modstri
    # n is setsize[s]


    ###################################################################################################################
    # step 1: collect all vectors across nested CV folds for each k

    k_collect = [None] * n_k

    for k in range(n_k):

        k_collect[k] = np.empty((f, 0), int)
        for sf in range(n_cv_folds):
            fold = (mf * n_cv_folds) + sf
            filestr = (filepath2use + str(fold))
            with open(filestr, "rb") as f:
                mod = pickle.load(f)

            if k == 0: # when there are only 2 clusters then only one beta vector is generated by the classifier.
                # to have one vector per cluster the betas are duplicated and flipped
                crit = np.nanmean(mod.allbetas[k], axis=1)
                crit = np.array([crit, -crit]).T
                criti = np.nanmean(mod.allitcpt[k])
                criti = np.array([criti, -criti]).T
            else:
                crit = np.nanmean(mod.allbetas[k], axis=2)
                criti = np.nanmean(mod.allitcpt[k], axis=1)
            if len(np.where(np.isnan(crit))[0])==len(crit):
                print('oops, the beta values are all NaN for k=' + str(k+2) + ' in ' + filestr)
                pass
            else:
                k_collect[k] = np.append(k_collect[k], crit, axis=1)
    # k_collect is a list with length n_k. k_collect[k] contains all beta vectors from all nested CV folds for models
    # with that k

    ###################################################################################################################
    # step 3: force k threshold
    avgclus = [None] * n_k
    for kthresh in range(n_k):
        avgclus[kthresh] = []
        for k in range(n_k):
            if k >= kthresh: # only apply this threshold if the original value of k was at least that big

                # cluster the vectors into x number of beta vector groups
                if link == 0:
                    clustering = AgglomerativeClustering(n_clusters=kthresh + 2, linkage='ward').fit(k_collect[k].T)
                elif link == 1:
                    clustering = AgglomerativeClustering(n_clusters=kthresh + 2, linkage='complete').fit(k_collect[k].T)
                elif link == 2:
                    clustering = AgglomerativeClustering(n_clusters=kthresh + 2, linkage='average').fit(k_collect[k].T)
                else:
                    print('please select linkage function')

                # for each beta vector group, get the average
                avgbs = np.full([k_collect[k].shape[0], kthresh + 2], np.nan)
                for c in range(kthresh + 2):
                    avgbs[:, c] = np.nanmean(k_collect[k][:, np.where(clustering.labels_ == c)[0]], axis=1)
                avgclus[kthresh].append(avgbs)
    # avgclus is a list with length n_k-1.
    # avgclus[k] is a list with length n_k-k
    # avgclus[k][z] contains the average for each of k groups of beta vectors based on models where the original
    # number of clusters was k-z+2

    ###################################################################################################################
    # step 4: calculate match between each solution
    averageerror = np.zeros(n_k)
    for kthresh in range(n_k):
        bestmatch = []
        for mf1 in range(len(avgclus[kthresh])):
            for mf2 in range(len(avgclus[kthresh])):
                if mf1 != mf2:

                    # for any two solutions that were aggregated down to the same number of clusters
                    # get the mse between every pair of vectors (each vector=the average of a group of beta vectors
                    # clustered together by the hierarchical clustering algorithm)
                    allmses = np.full([kthresh + 2, kthresh + 2], np.nan)
                    for c1 in range(kthresh + 2):
                        for c2 in range(kthresh + 2):
                            a = avgclus[kthresh][mf1][:, c1]
                            b = avgclus[kthresh][mf2][:, c2]
                            allmses[c1, c2] = vector_mse(a, b)

                    # go through the mse matrix and pick the lowest error value --> match those vectors and note the
                    # error, and then move on to find the next pair of best matching vectors never pulling the same
                    # vector twice
                    for c in range(kthresh + 2):
                        a = np.where(allmses == np.nanmin(allmses))
                        bestmatch.append(np.nanmin(allmses))
                        allmses[a[0][0], :] = np.nan
                        allmses[:, a[1][0]] = np.nan
        averageerror[kthresh] = np.nanmean(np.array(bestmatch))
    return averageerror